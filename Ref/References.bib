@inproceedings{Dev-Zero,
  author={Upasani, Nilam and Gaikwad, Ansh and Patel, Arshad and Modani, Nisha and Bijamwar, Prashanth and Patil, Sarvesh},
  booktitle={2021 International Conference on Communication information and Computing Technology (ICCICT)}, 
  title={Dev-Zero: A Chess Engine}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICCICT50803.2021.9510148}
  }

@mastersthesis{Classification,
    author    = {Jayasekara and M.G.P.B.},
    title     = {Classification of Chess Games and Players by Styles Using Game Data},
    school    = {University of Colombo School of Computing},
    ?_type     = {Masters thesis},
    ?_address  = {},
    year      = {2018},
    ?_month    = {},
    ?_note     = {},
}

@article{ResultAnalysisUsingElo,
    author    = {Thabtah F. and Padmavathy A. J. and Pritchard A.},
    title     = {Chess Results Analysis Using Elo Measure with
Machine Learning},
    journal   = {Journal of Information and Knowledge Management},
    ?_volume   = {19},
    ?_number   = {2},
    ?_pages    = {15},
    year      = {2020},
    ?_month    = {03},
    ?_note     = "",
}

@article{McIlroyYoung_Learning_Models_Chess_2022,
author = {McIlroy-Young, Reid and Sen, Siddhartha and Kleinberg, Jon and Anderson, Ashton},
doi = {10.1145/3534678.3539367},
journal = {KDD '22: Proceedings of the 28th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
month = {8},
title = {{Learning Models of Individual Behavior in Chess}},
year = {2022}
}

@inproceedings{SuperAI,
author = {McIlroy-Young, Reid and Sen, Siddhartha and Kleinberg, Jon and Anderson, Ashton},
title = {Aligning Superhuman AI with Human Behavior: Chess as a Model System},
booktitle={Aligning Superhuman AI with Human Behavior: Chess as a Model System},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403219},
doi = {10.1145/3394486.3403219},
pages = {1677–1687},
numpages = {11},
keywords = {human-ai collaboration, chess, action prediction},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@article{gpt-3,
    author    = {Floridi L. and Chiriatti M.},
    title     = {GPT‑3: Its Nature, Scope, Limits, and Consequences},
    journal   = {Minds and Machines},
    ?_volume   = {30},
    ?_pages    = {681–694},
    year      = {2020},
    ?_month    = {11},
    doi = {https://doi.org/10.1007/s11023-020-09548-1}
}

@article{gpt-3_turing,
    author    = {Elkins K. and Chun J.},
    title     = {Can GPT-3 Pass a Writer’s Turing Test?},
    journal   = {Cultural Analytics},
    year      = {2020},
    ?_month    = {09},
    doi = {https://doi.org/10.22148/001c.17212}
}

@misc{dall-e,
    author    = {Marcus G. and Davis E. and Aaronson S.},
    title     = {A very preliminary analysis of DALL-E 2},
    year      = {2022},
    ?_month    = {05},
    doi = {https://doi.org/10.48550/arXiv.2204.13807}
}

@misc{popularChessEngines,
    url={https://www.chess.com/terms/chess-engine},
    title={Most Popular Chess Engines},
    author = {chess.com},
    ?_note     = "Accessed: 5/12/2022",
    }

@InProceedings{alphazero,
  title = 	 {{ELF} {O}pen{G}o: an analysis and open reimplementation of {A}lpha{Z}ero},
  author =       {Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, Larry},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {6244--6253},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/tian19a/tian19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/tian19a.html},
  abstract = 	 {The AlphaGo, AlphaGo Zero, and AlphaZero series of algorithms are remarkable demonstrations of deep reinforcement learning’s capabilities, achieving superhuman performance in the complex game of Go with progressively increasing autonomy. However, many obstacles remain in the understanding of and usability of these promising approaches by the research community. Toward elucidating unresolved mysteries and facilitating future research, we propose ELF OpenGo, an open-source reimplementation of the AlphaZero algorithm. ELF OpenGo is the first open-source Go AI to convincingly demonstrate superhuman performance with a perfect (20:0) record against global top professionals. We apply ELF OpenGo to conduct extensive ablation studies, and to identify and analyze numerous interesting phenomena in both the model training and in the gameplay inference procedures. Our code, models, selfplay datasets, and auxiliary data are publicly available.}
}

@article{matchCentury,
    author    = {Hassabis, D.},
    title     = {Artificial Intelligence: Chess match of the century},
    journal   = {Nature},
    ?_volume   = {544},
    ?_pages    = {413–414},
    year      = {2017},
    ?_month    = {04},
    doi = {https://doi.org/10.1038/544413a}
}

@book{modernApproach,
    title= {Artificial intelligence: a modern approach},
    author = {Russell S. and Norvig P.},
    publisher={Pearson},
    year={2002}}

@INPROCEEDINGS{fingerprint,
  author={Gao, Ming and Hu, Xihong and Cao, Bo and Li, Dianxin},
  booktitle={2014 9th IEEE Conference on Industrial Electronics and Applications}, 
  title={Fingerprint sensors in mobile devices}, 
  year={2014},
  volume={},
  number={},
  pages={1437-1440},
  doi={10.1109/ICIEA.2014.6931394}}

@INPROCEEDINGS{humanlike,
    author={Robinson A. A.},
    title={Teaching AI to Play Chess Like People},
    booktitle={Computer Science Senior Seminar Spring 2021},
    year={2021}
    }

@book{nnChess,
    author={Dominik Klein},
    title={Neural Networks for Chess},
    booktitle={Neural Networks for Chess},
    year={2022},
    month={09},
    eprint={2209.01506},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
    }

@article{MasteringChessShogi,
  author       = {David Silver and
                  Thomas Hubert and
                  Julian Schrittwieser and
                  Ioannis Antonoglou and
                  Matthew Lai and
                  Arthur Guez and
                  Marc Lanctot and
                  Laurent Sifre and
                  Dharshan Kumaran and
                  Thore Graepel and
                  Timothy P. Lillicrap and
                  Karen Simonyan and
                  Demis Hassabis},
  title        = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
                  Learning Algorithm},
  journal      = {CoRR},
  volume       = {abs/1712.01815},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.01815},
  eprinttype    = {arXiv},
  eprint       = {1712.01815},
  timestamp    = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ComputerShogi,
title = {Computer shogi},
journal = {Artificial Intelligence},
volume = {134},
number = {1},
pages = {121-144},
year = {2002},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(01)00157-6},
url = {https://www.sciencedirect.com/science/article/pii/S0004370201001576},
author = {Hiroyuki Iida and Makoto Sakuta and Jeff Rollason},
keywords = {Shogi, Computer shogi, Alpha-beta search, Selective search, Quiescence search, Evaluation function},
abstract = {This paper describes the current state of the art in computer shogi. Shogi (Japanese chess) promises to be a good vehicle for future research into game-playing programs that are based on tree-searching paradigms. This paper shows where chess and shogi are similar, and details the important areas that make shogi programming of particular interest. A crucial difference is the game-tree complexity, which is significantly higher in shogi than in chess. Three important differences are the “drop” rule, the diverging character of the game, and the slow build-up of forces. They make it difficult to have effective opening and endgame procedures. After a short summary of the rules of shogi and an outline of the main areas of current work in computer shogi, we provide an overview of the history of computer shogi, in which computer-shogi activities both in human tournaments and in exhibition events are given. We conjecture that by the year 2010 a computer will be comparable in strength to the best human players. The most important techniques used in computer shogi are described. We focus on issues such as opening play, selective search, quiescence search, solving tactical exchanges without tree searching, position evaluation and endgame play. At the end the key challenges in computer shogi are enumerated, and finally, concluding remarks are given.}
}

@article{
Brown2019SuperhumanPA,
author = {Noam Brown  and Tuomas Sandholm },
title = {Superhuman AI for multiplayer poker},
journal = {Science},
volume = {365},
number = {6456},
pages = {885-890},
year = {2019},
doi = {10.1126/science.aay2400},
URL = {https://www.science.org/doi/abs/10.1126/science.aay2400},
eprint = {https://www.science.org/doi/pdf/10.1126/science.aay2400},
abstract = {Computer programs have shown superiority over humans in two-player games such as chess, Go, and heads-up, no-limit Texas hold'em poker. However, poker games usually include six players—a much trickier challenge for artificial intelligence than the two-player variant. Brown and Sandholm developed a program, dubbed Pluribus, that learned how to play six-player no-limit Texas hold'em by playing against five copies of itself (see the Perspective by Blair and Saffidine). When pitted against five elite professional poker players, or with five copies of Pluribus playing against one professional, the computer performed significantly better than humans over the course of 10,000 hands of poker. Science, this issue p. 885; see also p. 864 An AI dubbed Pluribus performs significantly better than human professionals in six-player no-limit Texas hold’em poker. In recent years there have been great strides in artificial intelligence (AI), with games often serving as challenge problems, benchmarks, and milestones for progress. Poker has served for decades as such a challenge problem. Past successes in such benchmarks, including poker, have been limited to two-player games. However, poker in particular is traditionally played with more than two players. Multiplayer games present fundamental additional issues beyond those in two-player games, and multiplayer poker is a recognized AI milestone. In this paper we present Pluribus, an AI that we show is stronger than top human professionals in six-player no-limit Texas hold’em poker, the most popular form of poker played by humans.}}

@inproceedings{maia,
  title={Improving the Strength of Human-Like Models in Chess},
  author={Hill, Saumik and Jain, Himanshu and Jain, Prateek},
  booktitle={Advances in Neural Information Processing Systems},
  pages={107--118},
  year={2020}
}

@article {stylometryChess,
    author ={McIlroy-Young, Reid and Sen, Siddhartha and Kleinberg, Jon and Anderson, Ashton and Wang, Russell},
    title = {Detecting Individual Decision-Making Style:
        Exploring Behavioral Stylometry in Chess},
    year = {2021},
    journal = {35th Conference on Neural Information Processing Systems (NeurIPS 2021)},
    url={https://arxiv.org/pdf/2208.01366.pdf}}

@article{ImageClass,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {ImageNet Classification with Deep Convolutional Neural Networks},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {60},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/3065386},
doi = {10.1145/3065386},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
journal = {Commun. ACM},
month = {may},
pages = {84–90},
numpages = {7}
}

@article{agileGrounded,
    author = {Hoda, R. and Noble, J. and Marshall, S.},
    title = {Developing a grounded theory to explain the practices of self-organizing Agile teams},
    year = {2012},
    journal = {Empirical Software Engineering},
    doi = {https://doi.org/10.1007/s10664-011-9161-0}
}

@inproceedings{mimicAI,
	doi = {10.1145/3514094.3534177},
  
	url = {https://doi.org/10.1145\%2F3514094.3534177},
  
	year = 2022,
	month = {jul},
  
	publisher = {ACM},
  
	author = {Reid McIlroy-Young and Jon Kleinberg and Siddhartha Sen and Solon Barocas and Ashton Anderson},
  
	title = {Mimetic Models},
  
	booktitle = {Proceedings of the 2022 {AAAI}/{ACM} Conference on {AI},
   Ethics, and Society}
}